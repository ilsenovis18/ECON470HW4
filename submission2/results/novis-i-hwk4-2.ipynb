{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ECON 470 Hwk4-2**\n",
    "\n",
    "**Author:** Ilse Novis \n",
    "\n",
    "**Due Date:** 4/9/2025  \n",
    "\n",
    "[GitHub Repository](https://github.com/ilsenovis18/ECON470HW4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ilsenovis/ECON470HW4/data/output/_final_ma_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rdd\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#python equivalent of rdrobust from R\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m final \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/ilsenovis/ECON470HW4/data/output/_final_ma_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ilsenovis/ECON470HW4/data/output/_final_ma_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.DtypeWarning)\n",
    "from rdd import rdd\n",
    "#python equivalent of rdrobust from R\n",
    "\n",
    "final = pd.read_csv('/Users/ilsenovis/ECON470HW4/data/output/final_ma_data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Remove all SNPs, 800-series plans, and prescription drug only plans (i.e., plans that do not offer Part C benefits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out SNPs, 800, drug only\n",
    "filtered = final[\n",
    "                 (final['snp'] == 'No') &\n",
    "                 ((final['planid'] < 800) | (final['planid'] >= 900)) &\n",
    "                 (final['partc_score'].notna())\n",
    "].copy()\n",
    " \n",
    " # Count plans per county per year\n",
    "plan_counts = (\n",
    "    filtered.groupby([\"year\", \"fips\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"plan_count\")\n",
    ")\n",
    "\n",
    "# Boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=plan_counts, x=\"year\", y=\"plan_count\")\n",
    "plt.title(\"Distribution of Plan Counts per County by Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Plan Count\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Plan Availability (Question 1)\n",
    "\n",
    "The boxplot showing the distribution of Medicare Advantage plan counts per county from 2010 to 2015 suggests considerable variation in the number of available plans:\n",
    "\n",
    "- **Sufficient for most**: The **median** number of plans per county is typically between **10 and 20**, indicating that most beneficiaries likely have **sufficient options** for choice.\n",
    "- **Too many in some counties**: A large number of **outliers** (some counties with over **100–200 plans**) suggest that in some regions, beneficiaries may face **too many options**, potentially leading to confusion or decision fatigue.\n",
    "- **Too few in others**: A smaller number of counties fall below the lower whisker of the distribution, indicating that in certain areas, there may be **too few plans** to ensure adequate choice or competition.\n",
    "\n",
    "**Conclusion**:  \n",
    "> Overall, the number of plans appears **sufficient on average**, but the wide variation across counties implies that **some areas may have too many options**, while **others may be underserved**. A more balanced distribution could improve both accessibility and decision-making for enrollees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Provide bar graphs showing the distribution of star ratings in 2010, 2012, and 2015. How has this distribution changed over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric\n",
    "filtered.loc[:, 'Star_Rating'] = pd.to_numeric(filtered['Star_Rating'], errors='coerce')\n",
    "years = [2010, 2012, 2015]\n",
    "\n",
    "# Create 1 row with 3 columns of subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 6), sharey=True)\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    ax = axes[i]\n",
    "    yearly_data = filtered[filtered['year'] == year]\n",
    "    sns.countplot(\n",
    "        data=yearly_data,\n",
    "        x='Star_Rating',\n",
    "        hue='Star_Rating',\n",
    "        palette='crest',\n",
    "        order=sorted(yearly_data['Star_Rating'].dropna().unique()),\n",
    "        ax=ax,\n",
    "        legend=False\n",
    "    )\n",
    "    ax.set_title(f\"Distribution of Star Ratings in {year}\", fontsize=16)\n",
    "    ax.set_xlabel(\"Star Rating\", fontsize=14)\n",
    "    ax.set_ylabel(\"Number of Plans\" if i == 0 else \"\", fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Star Rating Distributions (Question 2)\n",
    "\n",
    "The distribution of Medicare Advantage star ratings has changed **significantly** between 2010 and 2015:\n",
    "\n",
    "- **2010**: The majority of plans were concentrated at the **2.5-star** level, with relatively few plans rated 4 stars or higher. This suggests **overall lower quality scores** in the earlier period.\n",
    "  \n",
    "- **2012**: There was a noticeable **shift upward** in ratings. The number of 3-star and 3.5-star plans increased, and more plans started receiving 4 and 4.5 stars. The 2.5-star peak diminished compared to 2010.\n",
    "\n",
    "- **2015**: The distribution continued to shift toward **higher-quality ratings**. The modal rating moved to **4.0 stars**, with significant growth in 4.0 and 4.5-star plans. Plans rated below 3 stars became rare.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**:  \n",
    "Over time, the distribution of star ratings **shifted upward**, reflecting either genuine improvements in plan performance, changes in CMS methodology, or both. By 2015, **higher-rated plans dominated the market**, which may have important implications for consumer choice and financial bonuses tied to star ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Plot the average benchmark payment over time from 2010 through 2015. How much has the average benchmark payment risen over the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure ma_rate is numeric\n",
    "final[\"ma_rate\"] = pd.to_numeric(final[\"ma_rate\"], errors=\"coerce\")\n",
    "\n",
    "# Filter valid years and benchmark data\n",
    "benchmark_trend = (\n",
    "    final[(final['year'] >= 2010) & (final['year'] <= 2015) & (final['ma_rate'].notna())]\n",
    "    .groupby(\"year\", as_index=False)[\"ma_rate\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Plot average benchmark payment by year\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=benchmark_trend, x=\"year\", y=\"ma_rate\", marker=\"o\")\n",
    "plt.title(\"Average Benchmark Payment (2010–2015)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Average Benchmark Payment ($)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Average Benchmark Payment by Year:\")\n",
    "display(benchmark_trend)\n",
    "\n",
    "growth = benchmark_trend['ma_rate'].iloc[-1] - benchmark_trend['ma_rate'].iloc[0]\n",
    "print(f\"\\nIncrease from 2010 to 2015: ${growth:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in Average Benchmark Payment (2010–2015)\n",
    "\n",
    "Between 2010 and 2014, the average benchmark payment for Medicare Advantage plans **increased steadily**, reaching a peak of **$836.00** in 2014. However, in 2015 there was a sharp **drop** to **$782.71**.\n",
    "\n",
    "- **2010 Benchmark**: $803.94  \n",
    "- **2014 Peak**: $836.00  \n",
    "- **2015 Benchmark**: $782.71  \n",
    "\n",
    "**Overall Change (2010 to 2015)**:  \n",
    "The average benchmark payment **decreased by $21.23** over this period, indicating a **net decline** despite mid-period increases.\n",
    "\n",
    "This decline may reflect policy adjustments or cost-containment efforts within the Medicare Advantage program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Plot the average share of Medicare Advantage (relative to all Medicare eligibles) over time from 2010 through 2015. Has Medicare Advantage increased or decreased in popularity? How does this share correlate with benchmark payments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric just in case\n",
    "final[\"enrolled_mean\"] = pd.to_numeric(final[\"enrolled_mean\"], errors=\"coerce\")\n",
    "final[\"eligibles_mean\"] = pd.to_numeric(final[\"eligibles_mean\"], errors=\"coerce\")\n",
    "\n",
    "# Calculate Medicare Advantage (MA) share per plan\n",
    "final[\"ma_share\"] = final[\"enrolled_mean\"] / final[\"eligibles_mean\"]\n",
    "\n",
    "# Group by year to calculate average MA share across counties/plans\n",
    "ma_share_trend = (\n",
    "    final[(final[\"year\"] >= 2010) & (final[\"year\"] <= 2015) & (final[\"ma_share\"].notna())]\n",
    "    .groupby(\"year\", as_index=False)[\"ma_share\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Merge MA share trend and benchmark trend\n",
    "merged_trend = pd.merge(ma_share_trend, benchmark_trend, on=\"year\")\n",
    "\n",
    "# Create figure and primary y-axis\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot MA share on primary axis\n",
    "color1 = \"tab:blue\"\n",
    "ax1.set_xlabel(\"Year\")\n",
    "ax1.set_ylabel(\"MA Share\", color=color1)\n",
    "ax1.plot(merged_trend[\"year\"], merged_trend[\"ma_share\"], marker=\"o\", color=color1, label=\"MA Share\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color1)\n",
    "\n",
    "# Create secondary y-axis for benchmark payment\n",
    "ax2 = ax1.twinx()\n",
    "color2 = \"tab:green\"\n",
    "ax2.set_ylabel(\"Benchmark Payment ($)\", color=color2)\n",
    "ax2.plot(merged_trend[\"year\"], merged_trend[\"ma_rate\"], marker=\"o\", linestyle=\"--\", color=color2, label=\"Benchmark Payment\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color2)\n",
    "\n",
    "# Titles and layout\n",
    "plt.title(\"MA Share and Benchmark Payments (2010–2015)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Correlation\n",
    "correlation = merged_trend[\"ma_share\"].corr(merged_trend[\"ma_rate\"])\n",
    "print(f\"\\nCorrelation between MA share and benchmark payment: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity of Medicare Advantage and Its Relationship with Benchmark Payments\n",
    "\n",
    "**Has Medicare Advantage Increased in Popularity?**  \n",
    "Yes — the share of Medicare beneficiaries enrolled in Medicare Advantage (MA) plans **increased steadily from 2010 to 2015**. The MA share rose from under 10% in 2010 to over 15% by 2015, indicating growing popularity among eligible beneficiaries.\n",
    "\n",
    "**How Does This Share Correlate with Benchmark Payments?**  \n",
    "The correlation between MA share and benchmark payments is **very weak** (correlation coefficient = **0.043**). This suggests that while MA enrollment increased, it was **not strongly driven by changes in benchmark payment levels**.\n",
    "\n",
    "Other factors, such as plan availability, star ratings, or broader market trends, may better explain the increase in MA uptake during this period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate ATEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Calculate the running variable underlying the star rating. Provide a table showing the number of plans that are rounded up into a 3-star, 3.5-star, 4-star, 4.5-star, and 5-star rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to 2010 only\n",
    "data_2010 = final[final[\"year\"] == 2010].copy()\n",
    "\n",
    "# Define raw Star Rating based on Part D rules\n",
    "data_2010[\"Star_Rating\"] = np.where(\n",
    "    data_2010[\"partd\"] == \"No\",\n",
    "    data_2010[\"partc_score\"],\n",
    "    np.where(\n",
    "        data_2010[\"partcd_score\"].isna(),\n",
    "        data_2010[\"partc_score\"],\n",
    "        data_2010[\"partcd_score\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create rounded rating to nearest 0.5\n",
    "data_2010[\"rounded_rating\"] = np.round(data_2010[\"Star_Rating\"] * 2) / 2\n",
    "\n",
    "# Count number of plans by rounded rating\n",
    "rating_counts = data_2010[\"rounded_rating\"].value_counts().sort_index()\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "rating_counts_df = rating_counts.reset_index()\n",
    "rating_counts_df.columns = [\"Rounded Star Rating\", \"Number of Plans\"]\n",
    "\n",
    "# Show table\n",
    "print(\"Number of Plans by Rounded Star Rating (2010):\")\n",
    "display(rating_counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Using the RD estimator with a bandwidth of 0.125, provide an estimate of the effect of receiving a 3-star versus a 2.5 star rating on enrollments. Repeat the exercise to estimate the effects at 3.5 stars, and summarize your results in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Setup data_2010 and raw_rating\n",
    "data_2010 = final[final[\"year\"] == 2010].copy()\n",
    "\n",
    "data_2010[\"raw_rating\"] = np.where(\n",
    "    data_2010[\"partd\"] == \"No\",\n",
    "    data_2010[\"partc_score\"],\n",
    "    np.where(data_2010[\"partcd_score\"].isna(), data_2010[\"partc_score\"], data_2010[\"partcd_score\"])\n",
    ")\n",
    "\n",
    "data_2010[\"avg_enrolled\"] = pd.to_numeric(data_2010[\"avg_enrollment\"], errors=\"coerce\")\n",
    "\n",
    "# STEP 2: RD Estimation Function\n",
    "def rd_estimate(data, cutoff, bandwidth=0.125):\n",
    "    rd_data = data[\n",
    "        (data[\"raw_rating\"] >= cutoff - bandwidth) &\n",
    "        (data[\"raw_rating\"] <= cutoff + bandwidth)\n",
    "    ].copy()\n",
    "\n",
    "    rd_data[\"treatment\"] = (rd_data[\"raw_rating\"] >= cutoff).astype(int)\n",
    "    rd_data = rd_data.dropna(subset=[\"avg_enrolled\"])\n",
    "\n",
    "    X = sm.add_constant(rd_data[\"treatment\"])\n",
    "    y = rd_data[\"avg_enrolled\"]\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    return {\n",
    "        \"Cutoff\": cutoff,\n",
    "        \"Bandwidth\": bandwidth,\n",
    "        \"Estimated ATE\": model.params[\"treatment\"],\n",
    "        \"Standard Error\": model.bse[\"treatment\"],\n",
    "        \"N\": len(rd_data)\n",
    "    }\n",
    "\n",
    "# STEP 3: Run estimates\n",
    "results = [\n",
    "    rd_estimate(data_2010, cutoff=3.0, bandwidth=0.125),\n",
    "    rd_estimate(data_2010, cutoff=3.5, bandwidth=0.125)\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Repeat your results for bandwidhts of 0.1, 0.12, 0.13, 0.14, and 0.15 (again for 3 and 3.5 stars). Show all of the results in a graph. How sensitive are your findings to the choice of bandwidth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Reuse the rd_estimate function ---\n",
    "def rd_estimate(data, cutoff, bandwidth=0.125):\n",
    "    rd_data = data[\n",
    "        (data[\"raw_rating\"] >= cutoff - bandwidth) &\n",
    "        (data[\"raw_rating\"] <= cutoff + bandwidth)\n",
    "    ].copy()\n",
    "\n",
    "    rd_data[\"treatment\"] = (rd_data[\"raw_rating\"] >= cutoff).astype(int)\n",
    "    rd_data = rd_data.dropna(subset=[\"avg_enrolled\"])\n",
    "\n",
    "    X = sm.add_constant(rd_data[\"treatment\"])\n",
    "    y = rd_data[\"avg_enrolled\"]\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    return model.params[\"treatment\"], model.bse[\"treatment\"]\n",
    "\n",
    "# --- Step 2: Run RD for multiple bandwidths and cutoffs ---\n",
    "bandwidths = [0.1, 0.12, 0.13, 0.14, 0.15]\n",
    "results = []\n",
    "\n",
    "for bw in bandwidths:\n",
    "    for cutoff in [3.0, 3.5]:\n",
    "        ate, se = rd_estimate(data_2010, cutoff=cutoff, bandwidth=bw)\n",
    "        results.append({\n",
    "            \"Cutoff\": cutoff,\n",
    "            \"Bandwidth\": bw,\n",
    "            \"ATE\": ate,\n",
    "            \"SE\": se\n",
    "        })\n",
    "\n",
    "# --- Step 3: Convert to DataFrame ---\n",
    "rd_results = pd.DataFrame(results)\n",
    "\n",
    "# --- Step 4: Plot ATEs with error bars ---\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for cutoff, color in zip([3.0, 3.5], ['blue', 'green']):\n",
    "    subset = rd_results[rd_results[\"Cutoff\"] == cutoff]\n",
    "    ax.errorbar(\n",
    "        subset[\"Bandwidth\"], subset[\"ATE\"], yerr=subset[\"SE\"],\n",
    "        label=f'Cutoff {cutoff}', marker='o', linestyle='-', color=color, capsize=5\n",
    "    )\n",
    "\n",
    "# --- Step 5: Final Styling ---\n",
    "ax.set_title(\"RD Estimates of Star Rating on Enrollment\\nSensitivity to Bandwidth\", fontsize=14)\n",
    "ax.set_xlabel(\"Bandwidth\")\n",
    "ax.set_ylabel(\"Estimated ATE on Enrollment\")\n",
    "ax.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "ax.legend()\n",
    "plt.xticks(bandwidths)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Examine (graphically) whether contracts appear to manipulate the running variable. In other words, look at the distribution of the running variable before and after the relevent threshold values. What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prep the data\n",
    "final['partc_score'] = pd.to_numeric(final['partc_score'], errors='coerce')\n",
    "final['partcd_score'] = pd.to_numeric(final['partcd_score'], errors='coerce')\n",
    "\n",
    "# Focus on 2010\n",
    "rdd_data = final[final['year'] == 2010].copy()\n",
    "\n",
    "# Define running variable\n",
    "rdd_data['running_score'] = np.where(\n",
    "    rdd_data['partd'] == 'No',\n",
    "    rdd_data['partc_score'],\n",
    "    rdd_data['partcd_score']\n",
    ")\n",
    "\n",
    "# Keep only plans with valid running scores\n",
    "rdd_data = rdd_data[rdd_data['running_score'].notna()]\n",
    "\n",
    "# Function to plot density around cutoff\n",
    "def plot_density(data, cutoff, bandwidth=0.3):\n",
    "    window = data[\n",
    "        (data['running_score'] >= cutoff - bandwidth) &\n",
    "        (data['running_score'] <= cutoff + bandwidth)\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(window['running_score'], bins=40, kde=False, color=\"slateblue\", edgecolor=\"white\")\n",
    "    plt.axvline(cutoff, color='red', linestyle='--', label=f\"Cutoff = {cutoff}\")\n",
    "    plt.title(f\"Density of Running Variable Near Cutoff = {cutoff}\")\n",
    "    plt.xlabel(\"Running Score\")\n",
    "    plt.ylabel(\"Number of Plans\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Run for cutoffs 3.0 and 3.5\n",
    "plot_density(rdd_data, cutoff=3.0)\n",
    "plot_density(rdd_data, cutoff=3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the Running Variable Near Cutoffs\n",
    "\n",
    "To assess whether plans may be manipulating their reported star ratings around important thresholds (3.0 and 3.5), we examine the density of the raw running variable within a narrow bandwidth (±0.3) around each cutoff.\n",
    "\n",
    "The histograms near both the **3.0 and 3.5 cutoffs** appear smooth and continuous, with no visible jumps or clustering immediately above the thresholds.\n",
    "\n",
    "**What do we find?**\n",
    "\n",
    "There is **no clear evidence of manipulation** of the running variable around either threshold. The distributions are fairly symmetric and do not suggest strategic behavior by plans to achieve higher star ratings by just crossing the cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: Similar to question 4, examine whether plans just above the threshold values have different characteristics than contracts just below the threshold values. Use HMO and Part D status as your plan characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on 2010\n",
    "data_2010 = final[final[\"year\"] == 2010].copy()\n",
    "\n",
    "# If not already present, calculate raw rating (same logic used in earlier parts)\n",
    "data_2010[\"raw_rating\"] = np.where(\n",
    "    data_2010[\"partd\"] == \"No\",\n",
    "    data_2010[\"partc_score\"],\n",
    "    np.where(data_2010[\"partcd_score\"].isna(), data_2010[\"partc_score\"], data_2010[\"partcd_score\"])\n",
    ")\n",
    "\n",
    "# Function to summarize plan characteristics above/below RD cutoff\n",
    "def covariate_check(data, cutoff, bandwidth):\n",
    "    subset = data[\n",
    "        (data[\"raw_rating\"] >= cutoff - bandwidth) &\n",
    "        (data[\"raw_rating\"] <= cutoff + bandwidth)\n",
    "    ].copy()\n",
    "    \n",
    "    subset[\"above\"] = (subset[\"raw_rating\"] >= cutoff).astype(int)\n",
    "\n",
    "    summary = subset.groupby(\"above\").agg(\n",
    "        share_hmo=(\"plan_type\", lambda x: (x.str.upper() == \"HMO\").mean()),\n",
    "        share_partd=(\"partd\", lambda x: (x == \"Yes\").mean()),\n",
    "        n_plans=(\"contractid\", \"count\")\n",
    "    ).reset_index()\n",
    "\n",
    "    summary[\"group\"] = summary[\"above\"].map({0: f\"Below {cutoff}\", 1: f\"Above {cutoff}\"})\n",
    "    return summary[[\"group\", \"share_hmo\", \"share_partd\", \"n_plans\"]]\n",
    "\n",
    "# Run checks for both cutoffs\n",
    "cov_3 = covariate_check(data_2010, cutoff=3.0, bandwidth=0.125)\n",
    "cov_35 = covariate_check(data_2010, cutoff=3.5, bandwidth=0.125)\n",
    "\n",
    "# Combine into one table\n",
    "covariate_table = pd.concat([cov_3, cov_35], ignore_index=True)\n",
    "covariate_table.columns = [\"Group\", \"Share HMO\", \"Share Part D\", \"Number of Plans\"]\n",
    "\n",
    "# Display the table\n",
    "print(\"\\nCovariate Balance Around RD Thresholds (Bandwidth = 0.125)\")\n",
    "display(covariate_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: Question 10: Summarize your findings from 5-9. What is the effect of increasing a star rating on enrollments? Briefly explain your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Rounded Star Ratings (2010)\n",
    "rating_counts_df = pd.DataFrame({\n",
    "    \"Rounded Star Rating\": [2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0],\n",
    "    \"Number of Plans\": [431, 27549, 7419, 6347, 5453, 2459, 75]\n",
    "})\n",
    "\n",
    "# Question 6: RD Estimates at Cutoffs 3.0 and 3.5\n",
    "rd_estimates_df = pd.DataFrame({\n",
    "    \"Cutoff\": [3.0, 3.5],\n",
    "    \"Bandwidth\": [0.125, 0.125],\n",
    "    \"Estimated ATE\": [740.394199, 418.940257],\n",
    "    \"Standard Error\": [47.231624, 23.056193],\n",
    "    \"N (Sample Size)\": [3034, 2879]\n",
    "})\n",
    "\n",
    "# Question 9: Covariate Balance Around RD Thresholds\n",
    "covariate_balance_df = pd.DataFrame({\n",
    "    \"Group\": [\"Above 3.0\", \"Above 3.5\"],\n",
    "    \"Share HMO\": [0.0, 0.0],\n",
    "    \"Share Part D\": [0.893651, 0.853317],\n",
    "    \"Number of Plans\": [7419, 6347]\n",
    "})\n",
    "\n",
    "# Merge all into one summary table\n",
    "summary_combined = pd.DataFrame({\n",
    "    \"Cutoff\": [3.0, 3.5],\n",
    "    \"Rounded Star Rating Plan Count\": [\n",
    "        rating_counts_df[rating_counts_df[\"Rounded Star Rating\"] == 3.0][\"Number of Plans\"].values[0],\n",
    "        rating_counts_df[rating_counts_df[\"Rounded Star Rating\"] == 3.5][\"Number of Plans\"].values[0]\n",
    "    ],\n",
    "    \"Estimated ATE\": rd_estimates_df[\"Estimated ATE\"],\n",
    "    \"Standard Error\": rd_estimates_df[\"Standard Error\"],\n",
    "    \"N (Sample Size)\": rd_estimates_df[\"N (Sample Size)\"],\n",
    "    \"Share HMO\": covariate_balance_df[\"Share HMO\"],\n",
    "    \"Share Part D\": covariate_balance_df[\"Share Part D\"]\n",
    "})\n",
    "\n",
    "display(summary_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Findings from Questions 5–9\n",
    "\n",
    "The results from Questions 5 through 9 provide clear evidence that **increasing a plan’s star rating has a positive and significant effect on enrollment**:\n",
    "\n",
    "- At the **3.0 star cutoff**, crossing the threshold leads to an **increase of approximately 740 enrollees**, with a standard error of ~47.\n",
    "- At the **3.5 star cutoff**, the effect is smaller but still substantial, with an **increase of around 419 enrollees**, and a lower standard error of ~23.\n",
    "\n",
    "These effects are estimated using a regression discontinuity design (RDD), focusing on plans narrowly around each cutoff, where the assignment to treatment is as good as random.\n",
    "\n",
    "Additional checks (from Question 9) suggest that **plan characteristics like HMO status and Part D participation are balanced above and below each cutoff**, indicating the RDD assumptions are likely satisfied.\n",
    "\n",
    "Overall, the findings show that even **small increases in star ratings can lead to large gains in enrollment**, confirming that star ratings are a good signal to beneficiaries and have real market impact."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
